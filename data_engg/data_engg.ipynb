{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda16dab-f9cb-4df6-9209-bbe805c52b38",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e4d30-4857-41c3-a7e2-4e187919ff14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ETL vs ELT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5a5e4-3a47-45f2-ab67-d7619683d407",
   "metadata": {},
   "source": [
    "| Category                 | ETL                                                                                       | ELT                                                                                         |\n",
    "|--------------------------|-------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|\n",
    "| Definition               | Data is extracted from a source system, transformed on a secondary processing server, and loaded into a destination system. | Data is extracted from a source system, loaded into a destination system, and transformed inside the destination system. |\n",
    "| Extract                  | Raw data is extracted using API connectors.                                               | Raw data is extracted using API connectors.                                                 |\n",
    "| Transform                | Raw data is transformed on a processing server.                                           | Raw data is transformed inside the target system.                                           |\n",
    "| Load                     | Transformed data is loaded into a destination system.                                      | Raw data is loaded directly into the target system.                                         |\n",
    "| Speed                    | ETL is a time-intensive process; data is transformed before loading into a destination system. | ELT is faster by comparison; data is loaded directly into a destination system, and transformed in-parallel. |\n",
    "| Code-Based Transformations | Performed on secondary server. Best for compute-intensive transformations & pre-cleansing. | Transformations performed in-database; simultaneous load & transform; speed & efficiency.   |\n",
    "| Maturity                 | Modern ETL has existed for 20+ years; its practices & protocols are well-known and documented. | ELT is a newer form of data integration; less documentation & experience.                    |\n",
    "| Privacy                  | Pre-load transformation can eliminate PII (helps for HIPPA).                             | Direct loading of data requires more privacy safeguards.                                     |\n",
    "| Maintenance              | Secondary processing server adds to the maintenance burden.                               | With fewer systems, the maintenance burden is reduced.                                      |\n",
    "| Costs                    | Separate servers can create cost issues.                                                  | Simplified data stack costs less.                                                           |\n",
    "| Requeries                | Data is transformed before entering destination system; therefore raw data cannot be requeried. | Raw data is loaded directly into destination system and can be requeried endlessly.          |\n",
    "| Data Lake Compatibility  | No, ETL does not have data lake compatibility.                                            | Yes, ELT does have data lake compatibility.                                                 |\n",
    "| Data Output              | Structured (typically).                                                                   | Structured, semi-structured, unstructured.                                                  |\n",
    "| Data Volume              | Ideal for small data sets with complicated transformation requirements.                    | Ideal for large datasets that require speed & efficiency.                                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694990b-53a5-407d-923a-374b0c0acd60",
   "metadata": {},
   "source": [
    "<img src=\"https://rivery.io/wp-content/uploads/2020/05/ETL-Process-for-linkedin3-1024x535.png\" alt=\"ETL Process\" width=\"800\" height=\"600\">\n",
    "<img src=\"https://rivery.io/wp-content/uploads/2020/05/ETL-Process-for-linkedin.png\" alt=\"ELT Process\" width=\"800\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab297da-885c-4f5e-9278-163011ff6a76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Medallion architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a1a63-6378-4f66-bc2f-945572ecdd17",
   "metadata": {},
   "source": [
    "A medallion architecture is a data design pattern used to logically organize data in a lakehouse, with the goal of incrementally and progressively improving the structure and quality of data as it flows through each layer of the architecture (from Bronze ⇒ Silver ⇒ Gold layer tables). Medallion architectures are sometimes also referred to as \"multi-hop\" architectures.<br><br>\n",
    "**Bronze layer (raw data)**<br>\n",
    "The Bronze layer is where we land all the data from external source systems. The table structures in this layer correspond to the source system table structures \"as-is,\" along with any additional metadata columns that capture the load date/time, process ID, etc. The focus in this layer is quick Change Data Capture and the ability to provide an historical archive of source (cold storage), data lineage, auditability, reprocessing if needed without rereading the data from the source system.<br><br>\n",
    "**Silver layer (cleansed and conformed data)**<br>\n",
    "In the Silver layer of the lakehouse, the data from the Bronze layer is matched, merged, conformed and cleansed (\"just-enough\") so that the Silver layer can provide an \"Enterprise view\" of all its key business entities, concepts and transactions. (e.g. master customers, stores, non-duplicated transactions and cross-reference tables).\n",
    "In the lakehouse data engineering paradigm, typically the ELT methodology is followed vs. ETL - which means only minimal or \"just-enough\" transformations and data cleansing rules are applied while loading the Silver layer. Speed and agility to ingest and deliver the data in the data lake is prioritized, and a lot of project-specific complex transformations and business rules are applied while loading the data from the Silver to Gold layer.<br><br>\n",
    "**Gold layer (curated business-level tables)**<br>\n",
    "Data in the Gold layer of the lakehouse is typically organized in consumption-ready \"project-specific\" databases. The Gold layer is for reporting and uses more de-normalized and read-optimized data models with fewer joins. The final layer of data transformations and data quality rules are applied here. Final presentation layer of projects such as Customer Analytics, Product Quality Analytics, Inventory Analytics, Customer Segmentation, Product Recommendations, Marking/Sales Analytics etc. fit in this layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6ff4be-d4cf-4264-a93c-1b854a5510ab",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/0*6eF61H_5C_voZEuy.png\" alt=\"ETL Process\" width=\"800\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848b5f9-e7af-41a8-b388-463b86c04138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81936a-e8c7-4f79-9bce-fa0a48a83058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c5369-0f64-4096-b25e-0075b15678ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff0af4-dad4-400c-82cf-4a376b4c96db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebeb7df-2a26-4f45-b98f-490110b1f1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
